{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "_NASA_data_path = r'/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/Data/Nasa Data/portal.nccs.nasa.gov/datashare/gmao/geos-cf/v1/das/Y2021/M01/D08' # use your path\n",
    "airquality_files = glob.glob(_NASA_data_path + \"/GEOS-CF.v01.rpl.aqc_tavg*.nc4\")\n",
    "meteorological_files = glob.glob(_NASA_data_path + \"/GEOS-CF.v01.rpl.met_tavg*.nc4\")\n",
    "\n",
    "_thudohanoi_data_path = r'/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/Data/thudohanoi'\n",
    "_thudohanoi_files = glob.glob(_thudohanoi_data_path + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.open_dataset('./das/Y2018/M01/D01/GEOS-CF.v01.rpl.aqc_tavg_1hr_g1440x721_v1.20180101_0030z.nc4')\n",
    "# df = ds.to_dataframe()\n",
    "\n",
    "# ds_2 = xr.open_dataset('./das/Y2018/M01/D01/GEOS-CF.v01.rpl.met_tavg_1hr_g1440x721_x1.20180101_1030z.nc4')\n",
    "# df_2 = ds_2.to_dataframe()\n",
    "\n",
    "# ds_3 = xr.open_dataset('./MERRA2.20170101.A1.05x0625.AS.nc4')\n",
    "# df_3 = ds_3.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thudohanoi_df = pd.DataFrame()\n",
    "for file in _thudohanoi_files:\n",
    "    thudohanoi_df = thudohanoi_df.append(pd.read_csv(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'parameter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5c6e8029757e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mthudohanoi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parameter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_thudohanoi_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-5c6e8029757e>\u001b[0m in \u001b[0;36mprocess_thudohanoi_data\u001b[0;34m(thudohanoi_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_thudohanoi_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mthudohanoi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parameter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_thudohanoi_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthudohanoi_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6722\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6723\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6724\u001b[0;31m             \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6725\u001b[0m         )\n\u001b[1;32m   6726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m             )\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'parameter'"
     ]
    }
   ],
   "source": [
    "# def process_thudohanoi_data(thudohanoi_df):\n",
    "#     thudohanoi_df.reset_index(drop=True,inplace=True)\n",
    "#     thudohanoi_df = thudohanoi_df.groupby(['site_id', 'time', 'parameter']).sum()\n",
    "#     return thudohanoi_df\n",
    "# tmp_df = process_thudohanoi_data(thudohanoi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_site_data():\n",
    "    site_df = pd.read_csv(_thudohanoi_data_path + \"/Site_data/VN_site_data.csv\")\n",
    "    site_df.set_index('id', inplace=True)\n",
    "    return site_df\n",
    "\n",
    "def filter_location_data(df):\n",
    "    #Dau tien la filter cac location tren moitruongthudo\n",
    "    #Tiep theo la lay du lieu tren nasa cua cac filter location\n",
    "    site_df = read_site_data()\n",
    "    df.sort_index(level=['lat', 'lon'], ascending=[1,1], inplace=True)\n",
    "    df = df.loc[idx[21, 105.75,:]]\n",
    "    return df\n",
    "\n",
    "def filter_meteorological_data(df):\n",
    "    df = df.reset_index(level=1, drop=True)\n",
    "    df = df[['RH', 'T', 'TPREC', 'U', 'V']]\n",
    "    df.rename(columns={\"RH\": \"Relative Humidity\", \"T\": \"Temperature\", \"TPREC\": \"Precipitation\",\n",
    "                       \"U\": \"Eastward wind\", \"V\":\"Northward wind\"}, inplace=True)\n",
    "    return df\n",
    "def filter_airquality_data(df):\n",
    "    df = df.reset_index(level=1, drop=True)\n",
    "    df.rename(columns={'PM25_RH35_GCC': 'PM25'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "full_airquality_df = pd.DataFrame()\n",
    "for file in airquality_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    full_airquality_df = full_airquality_df.append(filter_airquality_data(ds.to_dataframe()))\n",
    "\n",
    "airquality_df = filter_location_data(full_airquality_df)\n",
    "\n",
    "full_meteorological_df = pd.DataFrame()\n",
    "for file in meteorological_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    full_meteorological_df = full_meteorological_df.append(filter_meteorological_data(ds.to_dataframe()))\n",
    "\n",
    "meteorological_df = filter_location_data(full_meteorological_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/Development/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#converse all units to ug/m3\n",
    "#all units but PM2.5 is mol/molair\n",
    "#Conversion method is from this article\n",
    "def converse_units(volume_mixing_ratio, polutant_name):\n",
    "    #Determine molecular mass of polutant\n",
    "    #Taken from Nasa document for data\n",
    "    switcher = {\n",
    "        'CO': 28.00,\n",
    "        'NO2': 46.00,\n",
    "        'O3': 48.00,\n",
    "        'SO2': 64.00\n",
    "    }\n",
    "    molecular_weight = switcher.get(polutant_name, np.nan)\n",
    "    \n",
    "    #change mol/mol air to ppm (10^-6 mol/mol air = 1 ppm)\n",
    "    ppm = volume_mixing_ratio / 10**-6\n",
    "    #Change ppmv to mg/m^3\n",
    "    result = 0.0409 * ppm * molecular_weight\n",
    "    #from kg to ug\n",
    "    result = result * 1000\n",
    "    return result\n",
    "\n",
    "for polutant_name in ['CO','NO2','O3','SO2']:\n",
    "    airquality_df.loc[:, polutant_name] = airquality_df.loc[:, polutant_name].apply(lambda x: converse_units(x, polutant_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://vanbanphapluat.co/quyet-dinh-1459-qd-tcmt-2019-ky-thuat-tinh-toan-va-cong-bo-chi-so-chat-luong-khong-khi-viet-nam\n",
    "def create_BP_df():\n",
    "    BP_Ii = [0,50,100,150,200,300,400,500]\n",
    "    BP_O3_1h = [0,160,200,300,400,800,1000,1200]\n",
    "    BP_O3_8h = [0,120,170,210,400]\n",
    "    BP_CO = [0,10000,30000,45000,60000,90000,120000,150000]\n",
    "    BP_SO2 = [0,125,350,550,800,1600,2100,2630]\n",
    "    BP_NO2 = [0,100,200,700,1200,2350,3100,3850]\n",
    "    BP_PM10 = [0,50,150,250,350,420,500,600]\n",
    "    BP_PM25 = [0,25,50,80,150,250,350,500]\n",
    "    BP = pd.DataFrame(data = [range(1,9),BP_Ii, BP_O3_1h, BP_O3_8h, BP_CO, BP_SO2, BP_NO2, BP_PM10, BP_PM25],\n",
    "                      index=['I','Ii','O3','O3_8h','CO','SO2','NO2','PM10','PM25'], dtype= np.int64)\n",
    "    BP = BP.transpose().set_index('I')\n",
    "    #Add a upper to calculate I = 8\n",
    "    BP.loc[9] = [999999,999999,999999,999999,999999,999999,999999,999999]\n",
    "    BP.index = BP.index.astype(np.int64)\n",
    "    return BP\n",
    "global_BP = create_BP_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cho vao bang BP, series gia tri 5 hop chat\n",
    "#Dau ra la 1 series gom co gia tri index cua 5 hop chat do\n",
    "#Dau ra lan luot cua cac chat [CO, NO2, O3, PM25, SO2]\n",
    "def calculate_BP_I(polutant_data, BP = create_BP_df()):\n",
    "    result_I = []\n",
    "    BP_polutant_column = BP.loc[:,polutant_data.name]\n",
    "    result_I = polutant_data.apply(lambda x: BP_polutant_column.ge(x).idxmax() - 1) \n",
    "    return result_I\n",
    "sample_series = airquality_df\n",
    "sample_series = sample_series.apply(lambda x: calculate_BP_I(x,global_BP), axis=0, result_type = 'broadcast')\n",
    "# sample_result = pd.DataFrame(sample_result, index=['lat', 'lon', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cong thuc tinh duoc lay tu duong link nay: \n",
    "#http://tapchimoitruong.vn/pages/article.aspx?item=New-calculation-of-the-Vi%E1%BB%87t-Nam-Air-Quality-Index-51306\n",
    "#http://cem.gov.vn/storage/news_file_attach/QD%201459%20TCMT%20ngay%2012.11.2019%20AQI.pdf\n",
    "#Cong thuc nay se lay input la 1 dataframe so do hop chat cho output ra 1 series gom so AQI cua moi gio (Lon nhat trong tat ca hop chat)\n",
    "def calculate_AQI_h(data = None, formular = 1):  \n",
    "    #Cong thuc 1 = ((Ii[i+1] - Ii[i])/ (BP[i+1] - BP[i]))* (C[h] - BP[i]) +Ii[i]\n",
    "    def calculate_AQI_formular(polutant_data, I, BP = global_BP):\n",
    "        result = []\n",
    "        for data in zip(polutant_data.index, polutant_data.values, I.values):\n",
    "            polutant_name, polutant_value, I = data\n",
    "            I = int(I)\n",
    "            try:\n",
    "                AQI = ((BP.loc[I + 1,'Ii'] - BP.loc[I, 'Ii']) / (BP.loc[I+1, polutant_name] - BP.loc[I, polutant_name])\n",
    "                                                   * (polutant_value - BP.loc[I, polutant_name])) + BP.loc[I, 'Ii']\n",
    "            except KeyError:\n",
    "                print(data)\n",
    "                if I == 0:\n",
    "                    AQI = 0\n",
    "                else:\n",
    "                    AQI = 500\n",
    "            result.append(AQI)\n",
    "        return result\n",
    "    \n",
    "    #VietNam system use 12 hours for nowcast, the current hour and 11 hours before.\n",
    "    def nowcast(polutant_data, element):\n",
    "        lat, lon, time = element.name\n",
    "            #Nhung cong viec can lam\n",
    "            #Get data for the hour and 12 hours behind it in the same spot\n",
    "        tmp_12h_data_storage = polutant_data.loc[\n",
    "            idx[lat, lon, time - pd.Timedelta(hours=12) : time]]\n",
    "            #Kiem tra xem trong 3 gio gan nhat thi it nhat 2 gio phai co so lieu\n",
    "            #Neu khong qua duoc check o tren thi so lieu tinh duoc dat la np.nan\n",
    "        if tmp_12h_data_storage.iloc[:3].isna().sum() > 2:\n",
    "            result = np.nan\n",
    "        elif len(tmp_12h_data_storage) < 4:\n",
    "            result = np.nan\n",
    "        else:\n",
    "            #Trong 12 gia tri do lay gia tri min va max\n",
    "            min_data = tmp_12h_data_storage.min()\n",
    "            max_data = tmp_12h_data_storage.max()\n",
    "            #Tinh Weight bang cach lay gia tri lon nhat chia gia tri nho\n",
    "            w = min_data / max_data\n",
    "            #Neu weight < 1/2 thi dat weight = 1/2\n",
    "            if w < 1/2:\n",
    "                w = 1/2\n",
    "            #Tinh gia tri nowcast dua theo cong thuc\n",
    "            nowcast = sum([(w**i) * tmp_12h_data_storage.iloc[i-1] for i in range(1,len(tmp_12h_data_storage)+1)]) / sum([(w**i) for i in range(1,len(tmp_12h_data_storage) + 1)])\n",
    "            #Add gia tri now cast vao ket qua tra ve\n",
    "            result = nowcast\n",
    "            print(tmp_12h_data_storage)\n",
    "        return result\n",
    "    #Init variable\n",
    "    idx = pd.IndexSlice\n",
    "    #Sort index to slice\n",
    "    data.sort_index(level=['lat','lon', 'time'], ascending=[1,1,1], inplace=True)\n",
    "    \n",
    "    #Air index number of all polutant data\n",
    "    \n",
    "    data.loc[:,['PM25']] = data.loc[:,['PM25']].apply((lambda x: nowcast(data.loc[:,'PM25'], x)), axis=1, result_type='broadcast')\n",
    "    I_number = data.apply((lambda x: calculate_BP_I(x, global_BP)), axis=0, result_type='broadcast')\n",
    "    \n",
    "    calculated_AQI = I_number.apply((lambda x: calculate_AQI_formular(data.loc[x.name, :], x, global_BP)),\n",
    "                                axis=1, result_type='broadcast')\n",
    "    calculated_AQI['AQI_h'] = calculated_AQI.max(axis=1)\n",
    "    calculated_AQI['AQI_h_Polutant'] = calculated_AQI.idxmax(axis=1)\n",
    "    calculated_AQI['AQI_h_I'] = I_number.max(axis=1)  \n",
    "    return calculated_AQI\n",
    "AQI = calculate_AQI_h(airquality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Lam 4 model:\n",
    "# Random forest\n",
    "# gradient boosting regression\n",
    "# decision tree regression\n",
    "# mlp regression'''\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "moon_dataset = make_moons(1000, noise = 0.4)\n",
    "X = moon_dataset[0]\n",
    "y = moon_dataset[1]\n",
    "\n",
    "rnd_clf = RandomForestRegressor(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "rnd_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators=3, learning_rate = 1.0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "#measure the validation error at each stage of training to find the optimal number of trees\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "         for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth = 2, n_estimators = bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree_reg = DecisionTreeRegressor(random_state = 0)\n",
    "cross_val_score(decision_tree_reg, X_train, y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mlp_reg = MLPRegressor(random_state=0, max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "mlp_reg.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
