{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Models are trained in google colab with batch_size of 200-700. For online prediction, we only need batch_size of 1.\n",
    "Here we recombined models in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get source folder and append to sys directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "PROJ_ROOT = os.path.join(os.pardir)\n",
    "print(os.path.abspath(PROJ_ROOT))\n",
    "src_dir = os.path.join(PROJ_ROOT, \"src\")\n",
    "sys.path.append(src_dir)\n",
    "# Data path example\n",
    "#pump_data_path = os.path.join(PROJ_ROOT,\n",
    "#                              \"data\",\n",
    "#                              \"raw\",\n",
    "#                              \"pumps_train_values.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sklearn\n",
    "import random\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# import tensorflow as tf\n",
    "import googleapiclient.discovery\n",
    "from google.api_core.client_options import ClientOptions\n",
    "import feedparser\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from google.cloud import storage\n",
    "from features import extract_features\n",
    "from data import create_load_transform_processed_data\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program/flask_app/flask-app-test-317210-bdec872c665d.json\"\n",
    "PROJECT = \"flask-app-test-317210\" # change for your GCP project\n",
    "REGION = \"us-central1\" # change for your GCP region (where your model is hosted)\n",
    "MODEL = ['hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5']\n",
    "\n",
    "def predict_json(project, region, model, instances, version=None):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the Cloud ML Engine Model is deployed.\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to Tensors.\n",
    "        version (str): version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the \n",
    "            model.\n",
    "    \"\"\"\n",
    "    # Create the ML Engine service object\n",
    "    prefix = \"{}-ml\".format(region) if region else \"ml\"\n",
    "    api_endpoint = \"https://{}.googleapis.com\".format(prefix)\n",
    "    client_options = ClientOptions(api_endpoint=api_endpoint)\n",
    "\n",
    "    # Setup model path\n",
    "    model_path = \"projects/{}/models/{}\".format(project, model)\n",
    "    if version is not None:\n",
    "        model_path += \"/versions/{}\".format(version)\n",
    "\n",
    "    # Create ML engine resource endpoint and input data\n",
    "    ml_resource = googleapiclient.discovery.build(\n",
    "        \"ml\", \"v1\", cache_discovery=False, client_options=client_options).projects()\n",
    "    # turn input into list (ML Engine wants JSON)\n",
    "    instances_list = instances.tolist()\n",
    "\n",
    "    input_data_json = {\"signature_name\": \"serving_default\",\n",
    "                       \"instances\": instances_list}\n",
    "\n",
    "    request = ml_resource.predict(name=model_path, body=input_data_json)\n",
    "    response = request.execute()\n",
    "\n",
    "    # # ALT: Create model api\n",
    "    # model_api = api_endpoint + model_path + \":predict\"\n",
    "    # headers = {\"Authorization\": \"Bearer \" + token}\n",
    "    # response = requests.post(model_api, json=input_data_json, headers=headers)\n",
    "\n",
    "    if \"error\" in response:\n",
    "        raise RuntimeError(response[\"error\"])\n",
    "\n",
    "    scaler = extract_features.load_scaler()\n",
    "    reverse_scaled_prediction = scaler.inverse_transform(response['predictions'])\n",
    "\n",
    "    return reverse_scaled_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     site_id                 time  AQI_h AQI_h_label  AQI_h_I  \\\n",
       "0         49  2021-07-01 02:00:00   31.0        Good        1   \n",
       "1         49  2021-07-01 03:00:00   31.0        Good        1   \n",
       "2         49  2021-07-01 04:00:00   31.0        Good        1   \n",
       "3         49  2021-07-01 05:00:00   24.0        Good        1   \n",
       "4         49  2021-07-01 06:00:00   28.0        Good        1   \n",
       "..       ...                  ...    ...         ...      ...   \n",
       "364       49  2021-07-16 22:00:00   57.0    Moderate        2   \n",
       "365       49  2021-07-16 23:00:00   61.0    Moderate        2   \n",
       "366       49  2021-07-17 00:00:00   59.0    Moderate        2   \n",
       "367       49  2021-07-17 01:00:00   54.0    Moderate        2   \n",
       "368       49  2021-07-17 02:00:00   40.0        Good        1   \n",
       "\n",
       "     Continous length  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "..                ...  \n",
       "364                 0  \n",
       "365                 0  \n",
       "366                 0  \n",
       "367                 0  \n",
       "368                 0  \n",
       "\n",
       "[369 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>site_id</th>\n      <th>time</th>\n      <th>AQI_h</th>\n      <th>AQI_h_label</th>\n      <th>AQI_h_I</th>\n      <th>Continous length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49</td>\n      <td>2021-07-01 02:00:00</td>\n      <td>31.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>2021-07-01 03:00:00</td>\n      <td>31.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49</td>\n      <td>2021-07-01 04:00:00</td>\n      <td>31.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49</td>\n      <td>2021-07-01 05:00:00</td>\n      <td>24.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49</td>\n      <td>2021-07-01 06:00:00</td>\n      <td>28.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>49</td>\n      <td>2021-07-16 22:00:00</td>\n      <td>57.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>49</td>\n      <td>2021-07-16 23:00:00</td>\n      <td>61.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>49</td>\n      <td>2021-07-17 00:00:00</td>\n      <td>59.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367</th>\n      <td>49</td>\n      <td>2021-07-17 01:00:00</td>\n      <td>54.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>49</td>\n      <td>2021-07-17 02:00:00</td>\n      <td>40.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>369 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Data path example\n",
    "processed_data_path = os.path.join(PROJ_ROOT,\n",
    "                             \"data\",\n",
    "                             \"processed\",\n",
    "                             \"past_data.csv\")\n",
    "data = pd.read_csv(processed_data_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_number = np.random.uniform(-15, 15, data.shape[0])\n",
    "data['AQI_h'] = data['AQI_h'].add(random_number, axis=0).round()\n",
    "data['AQI_h'] = data['AQI_h'].astype(float)\n",
    "data.to_csv(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             AQI_h AQI_h_label  AQI_h_I  Continous length\n",
       "site_id time                                                             \n",
       "49      2021-07-16 01:00:00   22.0        Good        1                 0\n",
       "        2021-07-16 02:00:00   30.0        Good        1                 0\n",
       "        2021-07-16 03:00:00   50.0        Good        1                 0\n",
       "        2021-07-16 04:00:00   46.0        Good        1                 0\n",
       "        2021-07-16 05:00:00   58.0    Moderate        2                 0\n",
       "        2021-07-16 06:00:00   75.0    Moderate        2                 0\n",
       "        2021-07-16 07:00:00   58.0    Moderate        2                 0\n",
       "        2021-07-16 08:00:00   46.0        Good        1                 0\n",
       "        2021-07-16 09:00:00   35.0        Good        1                 0\n",
       "        2021-07-16 10:00:00   34.0        Good        1                 0\n",
       "        2021-07-16 11:00:00   32.0        Good        1                 0\n",
       "        2021-07-16 12:00:00   28.0        Good        1                 0\n",
       "        2021-07-16 13:00:00   27.0        Good        1                 0\n",
       "        2021-07-16 14:00:00   26.0        Good        1                 0\n",
       "        2021-07-16 15:00:00   25.0        Good        1                 0\n",
       "        2021-07-16 16:00:00   23.0        Good        1                 0\n",
       "        2021-07-16 17:00:00   22.0        Good        1                 0\n",
       "        2021-07-16 18:00:00   29.0        Good        1                 0\n",
       "        2021-07-16 19:00:00   44.0        Good        1                 0\n",
       "        2021-07-16 20:00:00   53.0    Moderate        2                 0\n",
       "        2021-07-16 21:00:00   52.0    Moderate        2                 0\n",
       "        2021-07-16 22:00:00   57.0    Moderate        2                 0\n",
       "        2021-07-16 23:00:00   61.0    Moderate        2                 0\n",
       "        2021-07-17 00:00:00   59.0    Moderate        2                 0\n",
       "        2021-07-17 01:00:00   54.0    Moderate        2                 0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>AQI_h</th>\n      <th>AQI_h_label</th>\n      <th>AQI_h_I</th>\n      <th>Continous length</th>\n    </tr>\n    <tr>\n      <th>site_id</th>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"25\" valign=\"top\">49</th>\n      <th>2021-07-16 01:00:00</th>\n      <td>22.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 02:00:00</th>\n      <td>30.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 03:00:00</th>\n      <td>50.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 04:00:00</th>\n      <td>46.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 05:00:00</th>\n      <td>58.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 06:00:00</th>\n      <td>75.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 07:00:00</th>\n      <td>58.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 08:00:00</th>\n      <td>46.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 09:00:00</th>\n      <td>35.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 10:00:00</th>\n      <td>34.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 11:00:00</th>\n      <td>32.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 12:00:00</th>\n      <td>28.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 13:00:00</th>\n      <td>27.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 14:00:00</th>\n      <td>26.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 15:00:00</th>\n      <td>25.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 16:00:00</th>\n      <td>23.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 17:00:00</th>\n      <td>22.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 18:00:00</th>\n      <td>29.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 19:00:00</th>\n      <td>44.0</td>\n      <td>Good</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 20:00:00</th>\n      <td>53.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 21:00:00</th>\n      <td>52.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 22:00:00</th>\n      <td>57.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-16 23:00:00</th>\n      <td>61.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-17 00:00:00</th>\n      <td>59.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-17 01:00:00</th>\n      <td>54.0</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "def get_data_from_bucket_as_dataframe(filename=\"past_data.csv\"):\n",
    "    \"\"\"Read a blob\"\"\"\n",
    "    bucket_name = \"deep_learning_model_bucket\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(filename)\n",
    "    if blob.exists() == False:\n",
    "        return None\n",
    "\n",
    "    return_data = blob.download_as_text()\n",
    "    return_data = StringIO(return_data)\n",
    "    df = pd.read_csv(return_data, sep=\",\", header=0, index_col=False)\n",
    "    return df\n",
    "data_df = get_data_from_bucket_as_dataframe()\n",
    "data_df = data_df.tail(25)\n",
    "data_df = data_df.astype({'time': 'datetime64[ns]', 'AQI_h': 'float'})\n",
    "data_df.set_index(['site_id', 'time'], inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n5\n0 days 05:00:00\nFeature shape:  (13, 5, 34)\nLabel shape:  (13,)\nInput have been created\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 0.05660377,  0.        ,  0.        , ..., -0.8490566 ,\n",
       "         -0.8490566 , -0.8490566 ],\n",
       "        [-0.09433962,  0.        ,  0.        , ..., -0.5471698 ,\n",
       "         -0.5471698 , -0.5471698 ],\n",
       "        [ 0.35849056,  1.        ,  0.        , ..., -0.43396226,\n",
       "         -0.43396226, -0.43396226],\n",
       "        [ 1.        ,  1.        ,  0.        , ..., -0.2754717 ,\n",
       "         -0.2754717 , -0.2754717 ],\n",
       "        [ 0.35849056,  1.        ,  0.        , ..., -0.06289309,\n",
       "         -0.06289309, -0.06289309]],\n",
       "\n",
       "       [[-0.09433962,  0.        ,  0.        , ..., -0.5471698 ,\n",
       "         -0.5471698 , -0.5471698 ],\n",
       "        [ 0.35849056,  1.        ,  0.        , ..., -0.43396226,\n",
       "         -0.43396226, -0.43396226],\n",
       "        [ 1.        ,  1.        ,  0.        , ..., -0.2754717 ,\n",
       "         -0.2754717 , -0.2754717 ],\n",
       "        [ 0.35849056,  1.        ,  0.        , ..., -0.06289309,\n",
       "         -0.06289309, -0.06289309],\n",
       "        [-0.09433962,  0.        ,  0.        , ..., -0.00269542,\n",
       "         -0.00269542, -0.00269542]],\n",
       "\n",
       "       [[ 0.35849056,  1.        ,  0.        , ..., -0.43396226,\n",
       "         -0.43396226, -0.43396226],\n",
       "        [ 1.        ,  1.        ,  0.        , ..., -0.2754717 ,\n",
       "         -0.2754717 , -0.2754717 ],\n",
       "        [ 0.35849056,  1.        ,  0.        , ..., -0.06289309,\n",
       "         -0.06289309, -0.06289309],\n",
       "        [-0.09433962,  0.        ,  0.        , ..., -0.00269542,\n",
       "         -0.00269542, -0.00269542],\n",
       "        [-0.509434  ,  0.        ,  0.        , ..., -0.01415094,\n",
       "         -0.01415094, -0.01415094]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.8113208 ,  0.        ,  0.        , ..., -0.14236706,\n",
       "         -0.21383648, -0.21383648],\n",
       "        [-0.8490566 ,  0.        ,  0.        , ..., -0.15265866,\n",
       "         -0.1981132 , -0.2597968 ],\n",
       "        [-0.8867925 ,  0.        ,  0.        , ..., -0.23499142,\n",
       "         -0.21069182, -0.3018868 ],\n",
       "        [-0.9622642 ,  0.        ,  0.        , ..., -0.3070326 ,\n",
       "         -0.2893082 , -0.3408805 ],\n",
       "        [-1.        ,  0.        ,  0.        , ..., -0.4271012 ,\n",
       "         -0.3616352 , -0.379717  ]],\n",
       "\n",
       "       [[-0.8490566 ,  0.        ,  0.        , ..., -0.15265866,\n",
       "         -0.1981132 , -0.2597968 ],\n",
       "        [-0.8867925 ,  0.        ,  0.        , ..., -0.23499142,\n",
       "         -0.21069182, -0.3018868 ],\n",
       "        [-0.9622642 ,  0.        ,  0.        , ..., -0.3070326 ,\n",
       "         -0.2893082 , -0.3408805 ],\n",
       "        [-1.        ,  0.        ,  0.        , ..., -0.4271012 ,\n",
       "         -0.3616352 , -0.379717  ],\n",
       "        [-0.7358491 ,  0.        ,  0.        , ..., -0.6089194 ,\n",
       "         -0.47484276, -0.4162042 ]],\n",
       "\n",
       "       [[-0.8867925 ,  0.        ,  0.        , ..., -0.23499142,\n",
       "         -0.21069182, -0.3018868 ],\n",
       "        [-0.9622642 ,  0.        ,  0.        , ..., -0.3070326 ,\n",
       "         -0.2893082 , -0.3408805 ],\n",
       "        [-1.        ,  0.        ,  0.        , ..., -0.4271012 ,\n",
       "         -0.3616352 , -0.379717  ],\n",
       "        [-0.7358491 ,  0.        ,  0.        , ..., -0.6089194 ,\n",
       "         -0.47484276, -0.4162042 ],\n",
       "        [-0.16981132,  0.        ,  0.        , ..., -0.7084048 ,\n",
       "         -0.6194969 , -0.43396226]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "def create_input_for_model(df, timesteps=[1], target_hour=[1], test_output=False, dev_output=False, output_path=None, PROJ_ROOT=os.pardir):\n",
    "    \"\"\"From interim dataframe:\n",
    "        + add features\n",
    "        + split into chunks according to timesteps\n",
    "        + compressed and saved to output_path\n",
    "        + estimate number of created dataset = timesteps * target_hour\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Contains interim data.\n",
    "    timesteps : list of integer\n",
    "        Each timestep represent 1 dataset\n",
    "    target_hour : list of integer\n",
    "        the label for each timesteps\n",
    "    output_path : string\n",
    "        Destination directory the dataset will be created\n",
    "    \"\"\"\n",
    "    if output_path == None:\n",
    "        output_path == os.path.join(PROJ_ROOT,\n",
    "                                    \"data\",\n",
    "                                    \"model_input\")\n",
    "    for timesteps in timesteps:\n",
    "        for target_hour in target_hour:\n",
    "            # Create train, dev, test data\n",
    "            train_df = extract_features.create_and_save_scale_data(df, output_path=output_path).copy()\n",
    "            train_df = extract_features.add_features(train_df).copy()\n",
    "            if test_output is not False:\n",
    "                train_df, test_df = extract_features.generate_train_test_set_by_time(\n",
    "                    train_df)\n",
    "                test, y_test, multiclass_y_test = extract_features.data_preprocessing(\n",
    "                    test_df, target_hour, timesteps=timesteps)\n",
    "                create_load_transform_processed_data.reshape_array_and_save_to_path(\n",
    "                    test, y_test, path=output_path, timesteps=timesteps, target_hour=target_hour, data_type=\"test\")\n",
    "            if dev_output is not False:\n",
    "                train_df, dev_df = extract_features.generate_train_test_set_by_time(\n",
    "                    train_df)\n",
    "                dev, y_dev, multiclass_y_dev = extract_features.data_preprocessing(\n",
    "                    dev_df, target_hour, timesteps=timesteps)\n",
    "                create_load_transform_processed_data.reshape_array_and_save_to_path(\n",
    "                    dev, y_dev, path=output_path, timesteps=timesteps, target_hour=target_hour, data_type=\"dev\")\n",
    "\n",
    "            train, y_train, multiclass_y = extract_features.data_preprocessing(\n",
    "                train_df, target_hour, timesteps=timesteps)\n",
    "\n",
    "            # Save data to file\n",
    "            if output_path is not None:\n",
    "                create_load_transform_processed_data.reshape_array_and_save_to_path(\n",
    "                    train, y_train, path=output_path, timesteps=timesteps, target_hour=target_hour, data_type=\"train\")\n",
    "    train = train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    print(\"Input have been created\")\n",
    "    return train, y_train\n",
    "data_df = data_df.tail(48)\n",
    "predict_data, label = create_input_for_model(data_df, timesteps=[5], target_hour=[1])\n",
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 5, 34)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tmp_predict_data = predict_data[-1].copy()\n",
    "tmp_predict_data = np.reshape(tmp_predict_data, (1, predict_data.shape[1], predict_data.shape[2]))\n",
    "tmp_predict_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      31.0\n",
       "1      31.0\n",
       "2      31.0\n",
       "3      24.0\n",
       "4      28.0\n",
       "       ... \n",
       "364    57.0\n",
       "365    61.0\n",
       "366    59.0\n",
       "367    54.0\n",
       "368    40.0\n",
       "Name: AQI_h, Length: 369, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "past_prediction = get_data_from_bucket_as_dataframe(\n",
    "        filename=\"past_data.csv\")\n",
    "past_prediction['AQI_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([41.44885257, 34.36666909, 34.52255065, 33.09760285, 31.69491367])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "all_result = np.array([])\n",
    "for model in range(0,5):\n",
    "    preds = predict_json(project=PROJECT,\n",
    "                                region=REGION,\n",
    "                                model=MODEL[model],\n",
    "                                instances=tmp_predict_data)\n",
    "    all_result = np.append(all_result, preds)\n",
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's load and scale predicted data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Show graphs and stats here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "Summarize findings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('aqi': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  },
  "interpreter": {
   "hash": "42a6f2126429ef925a6fad1ea37228e960d97f17ff7e5115d7c9932b5f26640c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}