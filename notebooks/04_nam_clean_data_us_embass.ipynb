{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "PROJ_ROOT = os.path.join(os.pardir)\n",
    "print(os.path.abspath(PROJ_ROOT))\n",
    "src_dir = os.path.join(PROJ_ROOT, \"src\")\n",
    "sys.path.append(src_dir)\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%aimport features.calculate_AQI\n",
    "from features import calculate_AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to know the number of continuous values\n",
    "# So when we use chunker, we can refer to the starting point to know how many to skip if timeline is not continous after skipping\n",
    "# Basic idea: Loop through the dataframe, if it is continuous increase the continous counter and pos counter\n",
    "# If encounter uncontinous timeline (Encounter a nan value), find the lastpoint with a loop,\n",
    "# Then change the start position continous length column values to the continous counter.\n",
    "# Reset the continous counter and start counter\n",
    "# Result: at the start of each continous timeline, there will be a number which indicate how many step you need to skip if\n",
    "# you need to get to the next timeline\n",
    "\n",
    "def time_continous_marker(df):\n",
    "    df_copy = df.copy()\n",
    "    pos = 0\n",
    "    start_pos = 0\n",
    "    continous = 0\n",
    "    size = 24\n",
    "    length = df_copy.shape[0]\n",
    "    result_column = df_copy.columns.get_loc(\"Continous length\")\n",
    "    continous_column = df_copy.columns.get_loc(\"AQI_h\")\n",
    "    while pos < length:\n",
    "        try:\n",
    "            if df_copy.iloc[pos : pos + size, continous_column].isnull().sum() == 0:\n",
    "                while df_copy.iloc[pos : pos + size, continous_column].isnull().sum() == 0:\n",
    "                    pos += size\n",
    "                    continous += size\n",
    "            else:\n",
    "                while np.isnan(df_copy.iloc[pos, continous_column]) == False:\n",
    "                    continous += 1\n",
    "                    pos += 1\n",
    "                \n",
    "                df_copy.iloc[start_pos, result_column] = continous\n",
    "                continous = 0\n",
    "                while np.isnan(df_copy.iloc[pos, 1]) == True:\n",
    "                    pos += 1\n",
    "                start_pos = pos\n",
    "#             print(pos)\n",
    "        except IndexError:\n",
    "            df_copy.iloc[start_pos, result_column] = continous\n",
    "            continous = 0\n",
    "            print(\"Current position is: {}\".format(pos))\n",
    "            pos = length\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             PM25\n",
       "site_id time                     \n",
       "49      2016-02-05 14:00:00  45.0\n",
       "        2016-02-05 15:00:00  27.0\n",
       "        2016-02-05 16:00:00  41.0\n",
       "        2016-02-05 17:00:00  41.0\n",
       "        2016-02-05 18:00:00  41.0\n",
       "...                           ...\n",
       "        2021-06-30 20:00:00  17.0\n",
       "        2021-06-30 21:00:00  21.0\n",
       "        2021-06-30 22:00:00  19.0\n",
       "        2021-06-30 23:00:00  14.0\n",
       "        2021-07-01 00:00:00  25.0\n",
       "\n",
       "[47339 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>PM25</th>\n    </tr>\n    <tr>\n      <th>site_id</th>\n      <th>time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"11\" valign=\"top\">49</th>\n      <th>2016-02-05 14:00:00</th>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 15:00:00</th>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 16:00:00</th>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 17:00:00</th>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 18:00:00</th>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 20:00:00</th>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 21:00:00</th>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 22:00:00</th>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 23:00:00</th>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-01 00:00:00</th>\n      <td>25.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>47339 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# TP HCM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "_HCM_us_embass_raw_data_path = os.path.join(PROJ_ROOT,\n",
    "                             \"data\",\n",
    "                             \"external\",\n",
    "                             \"us_embass\",\n",
    "                             \"raw\")\n",
    "\n",
    "_HCM_us_embass_data_files = glob.glob(_HCM_us_embass_raw_data_path + '/HoChiMinhCity_*YT*.csv')\n",
    "USEm_HCM_df = pd.DataFrame()\n",
    "for file in _HCM_us_embass_data_files:\n",
    "    USEm_HCM_df = USEm_HCM_df.append(pd.read_csv(file, parse_dates=True))\n",
    "\n",
    "# Remove site year 2015 because inconsistency data\n",
    "# daisuquanmy_df = daisuquanmy_df[(daisuquanmy_df['Year'] != 2015)]\n",
    "USEm_HCM_df.drop(columns=['Site', 'Parameter', 'AQI', 'AQI Category','NowCast Conc.', 'Conc. Unit', 'Duration'], inplace=True)\n",
    "USEm_HCM_df['Date (LT)'] = pd.to_datetime(USEm_HCM_df['Date (LT)'])\n",
    "USEm_HCM_df = USEm_HCM_df.rename(columns={'Date (LT)': 'time'})\n",
    "# Remove duplicate, fill in missing index and set ['Date (LT)'] as index and sort\n",
    "USEm_HCM_df.drop_duplicates(subset =\"time\", \n",
    "                     keep = \"first\", inplace = True)\n",
    "USEm_HCM_df = USEm_HCM_df.sort_values(by=['time'])\n",
    "USEm_HCM_df = USEm_HCM_df.set_index('time').asfreq('H').sort_index()\n",
    "USEm_HCM_df.reset_index(drop=False, inplace=True)\n",
    "USEm_HCM_df['site_id'] = 49\n",
    "USEm_HCM_df = USEm_HCM_df.set_index(['site_id', 'time'])\n",
    "# For all Raw Conc <= 0 QC Name must be Missing. Raw Conc change to -999\n",
    "USEm_HCM_df.loc[USEm_HCM_df['Raw Conc.'] <= 0, 'Raw Conc.'] = -999\n",
    "USEm_HCM_df.loc[USEm_HCM_df['Raw Conc.'] >= 600, 'Raw Conc.'] = -999\n",
    "USEm_HCM_df.loc[USEm_HCM_df['Raw Conc.'] <= 0, 'QC Name'] = 'Missing'\n",
    "\n",
    "USEm_HCM_df = USEm_HCM_df.replace(-999, np.nan)\n",
    "# Change Raw Conc to PM25\n",
    "USEm_HCM_df.rename(columns={'Raw Conc.': 'PM25'}, inplace=True)\n",
    "# Fill missing data\n",
    "USEm_HCM_df.fillna(method='ffill', limit=2, inplace=True)\n",
    "USEm_HCM_df.fillna(method='bfill', limit=2, inplace=True)\n",
    "\n",
    "# For year 2015 only, take data after 2015-12-09 14:00:00\n",
    "USEm_HCM_df = USEm_HCM_df.loc[USEm_HCM_df.index.get_level_values(1) >= pd.to_datetime(\"2016-02-05 02:00 PM\")]\n",
    "USEm_HCM_df = USEm_HCM_df[['PM25']]\n",
    "\n",
    "# USEm_HCM_df['PM25'] = USEm_HCM_df['PM25'].interpolate()\n",
    "\n",
    "USEm_HCM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Old site ids: [49]\n",
      "New site ids: [49]\n"
     ]
    }
   ],
   "source": [
    "AQI = calculate_AQI.calculate_AQI_h(USEm_HCM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current position is: 47340\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             PM25  AQI_h AQI_h_Polutant  AQI_h_I AQI_h_label  \\\n",
       "site_id time                                                                   \n",
       "49      2016-02-05 15:00:00  68.0   68.0           PM25      2.0    Moderate   \n",
       "        2016-02-05 16:00:00  75.0   75.0           PM25      2.0    Moderate   \n",
       "        2016-02-05 17:00:00  78.0   78.0           PM25      2.0    Moderate   \n",
       "        2016-02-05 18:00:00  80.0   80.0           PM25      2.0    Moderate   \n",
       "        2016-02-06 21:00:00  49.0   49.0           PM25      1.0        Good   \n",
       "...                           ...    ...            ...      ...         ...   \n",
       "        2021-06-30 20:00:00  36.0   36.0           PM25      1.0        Good   \n",
       "        2021-06-30 21:00:00  39.0   39.0           PM25      1.0        Good   \n",
       "        2021-06-30 22:00:00  39.0   39.0           PM25      1.0        Good   \n",
       "        2021-06-30 23:00:00  33.0   33.0           PM25      1.0        Good   \n",
       "        2021-07-01 00:00:00  42.0   42.0           PM25      1.0        Good   \n",
       "\n",
       "                             Continous length  \n",
       "site_id time                                   \n",
       "49      2016-02-05 15:00:00               4.0  \n",
       "        2016-02-05 16:00:00               0.0  \n",
       "        2016-02-05 17:00:00               0.0  \n",
       "        2016-02-05 18:00:00               0.0  \n",
       "        2016-02-06 21:00:00             103.0  \n",
       "...                                       ...  \n",
       "        2021-06-30 20:00:00               0.0  \n",
       "        2021-06-30 21:00:00               0.0  \n",
       "        2021-06-30 22:00:00               0.0  \n",
       "        2021-06-30 23:00:00               0.0  \n",
       "        2021-07-01 00:00:00               0.0  \n",
       "\n",
       "[46051 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>PM25</th>\n      <th>AQI_h</th>\n      <th>AQI_h_Polutant</th>\n      <th>AQI_h_I</th>\n      <th>AQI_h_label</th>\n      <th>Continous length</th>\n    </tr>\n    <tr>\n      <th>site_id</th>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"11\" valign=\"top\">49</th>\n      <th>2016-02-05 15:00:00</th>\n      <td>68.0</td>\n      <td>68.0</td>\n      <td>PM25</td>\n      <td>2.0</td>\n      <td>Moderate</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 16:00:00</th>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>PM25</td>\n      <td>2.0</td>\n      <td>Moderate</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 17:00:00</th>\n      <td>78.0</td>\n      <td>78.0</td>\n      <td>PM25</td>\n      <td>2.0</td>\n      <td>Moderate</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-05 18:00:00</th>\n      <td>80.0</td>\n      <td>80.0</td>\n      <td>PM25</td>\n      <td>2.0</td>\n      <td>Moderate</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2016-02-06 21:00:00</th>\n      <td>49.0</td>\n      <td>49.0</td>\n      <td>PM25</td>\n      <td>1.0</td>\n      <td>Good</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 20:00:00</th>\n      <td>36.0</td>\n      <td>36.0</td>\n      <td>PM25</td>\n      <td>1.0</td>\n      <td>Good</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 21:00:00</th>\n      <td>39.0</td>\n      <td>39.0</td>\n      <td>PM25</td>\n      <td>1.0</td>\n      <td>Good</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 22:00:00</th>\n      <td>39.0</td>\n      <td>39.0</td>\n      <td>PM25</td>\n      <td>1.0</td>\n      <td>Good</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-06-30 23:00:00</th>\n      <td>33.0</td>\n      <td>33.0</td>\n      <td>PM25</td>\n      <td>1.0</td>\n      <td>Good</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-01 00:00:00</th>\n      <td>42.0</td>\n      <td>42.0</td>\n      <td>PM25</td>\n      <td>1.0</td>\n      <td>Good</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>46051 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "AQI_new = AQI.copy()\n",
    "AQI_new.loc[AQI['AQI_h'] <= 0, 'AQI_h'] = np.NAN\n",
    "AQI_new['Continous length'] = 0\n",
    "max_time = AQI_new.index.get_level_values(1).max() + pd.Timedelta(hours=1)\n",
    "AQI_new = AQI_new.append(pd.Series(name=(49, max_time), dtype=float))\n",
    "AQI_new = time_continous_marker(AQI_new)\n",
    "AQI_new = AQI_new.dropna(subset=['AQI_h'])\n",
    "AQI_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "_HCM_us_embass_processed_data_path = os.path.join(PROJ_ROOT,\n",
    "                             \"data\",\n",
    "                             \"external\",\n",
    "                             \"us_embass\",\n",
    "                             \"processed\")\n",
    "AQI_new.to_csv(_HCM_us_embass_processed_data_path + \"/hcm_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now chunker need to be able to output chunks of train data and target in correct order\n",
    "# Basic ideas: loop through each chunk of data (size is size with ,\n",
    "# if the timeline is continous, add data to chunk_data [pos: pos+size]\n",
    "# add data to target [pos+size+target_hour]\n",
    "# if the timeline is not, skip pos according to size\n",
    "# Repeat below till timeline is continous\n",
    "# if after skipping, the timeline is still not continous, skip pos according to continous length colunmns\n",
    "from IPython.core.debugger import set_trace\n",
    "def chunker(seq, size, target_hour, debug = True):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        + Dataframe with PM25, AQI_h, AQI_h_I, Continous length and some other columns\n",
    "            - If data doesn't have Continous length columns, add 1 to data\n",
    "            - Take only PM25, date columns as train\n",
    "            - Take only AQI_h, AQI_h_I as target\n",
    "        + size: length of each chunk\n",
    "        + target_hour: labels for the hour which will be predicted\n",
    "    Ouput: 2 lists: chunk_data, target\n",
    "        + chunk_data: original data chunked to a specific timestep, have shape [..., timeframe, features]\n",
    "        + target: Label for each chunked train/test data, have shape [..., 1]\n",
    "    \"\"\"\n",
    "    if not 'Continous length' in seq.columns:\n",
    "        seq['Continous length'] = 0\n",
    "\n",
    "    timerange = pd.Timedelta(hours=size + target_hour)\n",
    "    chunk_data = []\n",
    "    target = []\n",
    "    multiclass_target = []\n",
    "    pos = 0\n",
    "    length = seq.shape[0]\n",
    "    while pos < (length - size):\n",
    "        try:\n",
    "            if seq.iloc[pos + size + target_hour].name[1] - seq.iloc[pos].name[1] == timerange:\n",
    "                while seq.iloc[pos + size + target_hour].name[1] - seq.iloc[pos].name[1] == timerange:\n",
    "                    chunk_data.append(seq.iloc[pos:pos + size].loc['PM25','Hour','Day of Week'])\n",
    "                    target.append(seq.iloc[pos + size + target_hour].loc['AQI_h'])\n",
    "                    multiclass_target.append(seq.iloc[pos + size + target_hour].loc['AQI_h_I'])\n",
    "                    pos += 1\n",
    "                    if pos + size + target_hour >= length - size:\n",
    "                        print(\"Returned\")\n",
    "                        return np.array(chunk_data), np.array(target), np.array(multiclass_target)\n",
    "            else:\n",
    "                tmp_pos = pos + size + target_hour\n",
    "                while seq.iloc[tmp_pos + size + target_hour].name[1] - seq.iloc[tmp_pos].name[1] != timerange:\n",
    "                    tmp_pos += int(seq.iloc[tmp_pos, 6])\n",
    "                print(\"Jump from {} to {}\".format(pos, tmp_pos))\n",
    "                pos = tmp_pos\n",
    "        except IndexError:\n",
    "            print(\"Current position is: {}\".format(pos))\n",
    "            print(\"Current tmp position is: {}\".format(tmp_pos))\n",
    "            pos = length - size\n",
    "    print(\"Returned\")\n",
    "    return np.array(chunk_data), np.array(target), np.array(multiclass_target)\n",
    "chunk_data, target, multiclass_target = chunker(AQI_copy, 12, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('aqi': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.517px",
    "left": "1154px",
    "right": "20px",
    "top": "314px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  },
  "interpreter": {
   "hash": "42a6f2126429ef925a6fad1ea37228e960d97f17ff7e5115d7c9932b5f26640c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}