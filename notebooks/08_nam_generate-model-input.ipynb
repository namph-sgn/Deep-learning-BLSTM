{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "State notebook purpose here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get source folder and append to sys directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "PROJ_ROOT = os.path.join(os.pardir)\n",
    "print(os.path.abspath(PROJ_ROOT))\n",
    "src_dir = os.path.join(PROJ_ROOT, \"src\")\n",
    "sys.path.append(src_dir)\n",
    "# Data path example\n",
    "#pump_data_path = os.path.join(PROJ_ROOT,\n",
    "#                              \"data\",\n",
    "#                              \"raw\",\n",
    "#                              \"pumps_train_values.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import glob\n",
    "import xarray as xr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import holidays\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 1\n",
    "# Use %aimport module to reload each module\n",
    "\n",
    "# Extract Data\n",
    "# %aimport features.extract_features\n",
    "from features import extract_features\n",
    "%aimport data.create_input_for_models\n",
    "from data import create_load_transform_processed_data, create_input_for_models\n",
    "# Make dataset\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Modeling\n",
    "Do work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get interim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Currently processing file \n",
      "../data/interim/30.csv\n",
      "Currently processing file \n",
      "../data/interim/9.csv\n",
      "Currently processing file \n",
      "../data/interim/32.csv\n",
      "Currently processing file \n",
      "../data/interim/11.csv\n",
      "Currently processing file \n",
      "../data/interim/40.csv\n",
      "Currently processing file \n",
      "../data/interim/28.csv\n",
      "Currently processing file \n",
      "../data/interim/49.csv\n",
      "Currently processing file \n",
      "../data/interim/46.csv\n",
      "Currently processing file \n",
      "../data/interim/10.csv\n",
      "Currently processing file \n",
      "../data/interim/8.csv\n",
      "Currently processing file \n",
      "../data/interim/25.csv\n",
      "Currently processing file \n",
      "../data/interim/7.csv\n",
      "Currently processing file \n",
      "../data/interim/16.csv\n",
      "Currently processing file \n",
      "../data/interim/42.csv\n",
      "Currently processing file \n",
      "../data/interim/44.csv\n",
      "Currently processing file \n",
      "../data/interim/37.csv\n",
      "Currently processing file \n",
      "../data/interim/1.csv\n",
      "Currently processing file \n",
      "../data/interim/13.csv\n",
      "Currently processing file \n",
      "../data/interim/31.csv\n",
      "Currently processing file \n",
      "../data/interim/26.csv\n",
      "Currently processing file \n",
      "../data/interim/12.csv\n",
      "Currently processing file \n",
      "../data/interim/15.csv\n",
      "Currently processing file \n",
      "../data/interim/39.csv\n",
      "Currently processing file \n",
      "../data/interim/14.csv\n",
      "Currently processing file \n",
      "../data/interim/47.csv\n",
      "Currently processing file \n",
      "../data/interim/48.csv\n",
      "Currently processing file \n",
      "../data/interim/33.csv\n",
      "Currently processing file \n",
      "../data/interim/27.csv\n",
      "Currently processing file \n",
      "../data/interim/41.csv\n",
      "Currently processing file \n",
      "../data/interim/24.csv\n",
      "Currently processing file \n",
      "../data/interim/35.csv\n",
      "Currently processing file \n",
      "../data/interim/43.csv\n",
      "Currently processing file \n",
      "../data/interim/45.csv\n",
      "Currently processing file \n",
      "../data/interim/34.csv\n",
      "Currently processing file \n",
      "../data/interim/29.csv\n",
      "Currently processing file \n",
      "../data/interim/38.csv\n",
      "Currently processing file \n",
      "../data/interim/36.csv\n"
     ]
    }
   ],
   "source": [
    "_interim_data_path = os.path.join(PROJ_ROOT,\n",
    "                                  \"data\",\n",
    "                                  \"interim\")\n",
    "_interim_files = glob.glob(_interim_data_path + '/*.csv')\n",
    "\n",
    "interim_df = pd.DataFrame()\n",
    "for file in _interim_files:\n",
    "    print('Currently processing file \\n{}'.format(file))\n",
    "    interim_df = interim_df.append(pd.read_csv(file, parse_dates=True, index_col=['site_id', 'time'],\n",
    "                                                     dtype={'CO': np.float64, 'NO2': np.float64, 'PM25': np.float64,\n",
    "                                                            'AQI_h': np.float64, 'AQI_h_I': np.int, 'site_id': np.int}))\n",
    "# Site 16 have many inconsistency in data so we remove it\n",
    "interim_df = interim_df[(interim_df.index.get_level_values(0) != 16)]\n",
    "# Get only columns we need\n",
    "interim_df = interim_df[['PM25', 'AQI_h', 'AQI_h_Polutant', 'AQI_h_I',\n",
    "       'AQI_h_label', 'Continous length']]\n",
    "# Ho Chi Minh data is on site 49\n",
    "hanoi_df = interim_df[(interim_df.index.get_level_values(0) != 49)].copy()\n",
    "hcm_df = interim_df[(interim_df.index.get_level_values(0) == 49)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input for model from interim data and put in to processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n5\n0 days 09:00:00\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d0e7f0466d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_input_for_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhcm_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_hour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_hour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model_input_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROJ_ROOT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJ_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program/notebooks/../src/data/create_input_for_models.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(df, timesteps, target_hour, test_output, dev_output, output_path, PROJ_ROOT)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 train_df, test_df = extract_features.generate_train_test_set_by_time(\n\u001b[1;32m     34\u001b[0m                     train_df)\n\u001b[0;32m---> 35\u001b[0;31m                 test, y_test, multiclass_y_test = extract_features.data_preprocessing(\n\u001b[0m\u001b[1;32m     36\u001b[0m                     test_df, target_hour, timesteps=timesteps)\n\u001b[1;32m     37\u001b[0m                 create_load_transform_processed_data.reshape_array_and_save_to_path(\n",
      "\u001b[0;32m/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program/src/features/extract_features.py\u001b[0m in \u001b[0;36mdata_preprocessing\u001b[0;34m(df, hour, timesteps, debug)\u001b[0m\n\u001b[1;32m    105\u001b[0m             generator = chunker_special(\n\u001b[1;32m    106\u001b[0m                 seq=tmp, target_hour=hour, size=timesteps, feature_cols=feature_cols)\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass_tmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/4ba37af6-51fd-47bc-8321-8c500c229114/study/School/KHOA LUAN TOT NGHIEP/runnable_program/src/features/extract_features.py\u001b[0m in \u001b[0;36mchunker_special\u001b[0;34m(seq, target_hour, size, feature_cols, target_cols, debug)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_hour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtimerange\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;32mwhile\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_hour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtimerange\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                         chunk_tmp = seq.iloc[pos:pos +\n\u001b[1;32m     69\u001b[0m                                              size].loc[:, feature_cols]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_model_input_data_path = os.path.join(PROJ_ROOT,\n",
    "                                   \"data\",\n",
    "                                   \"model_input\",\n",
    "                                   \"final_hcm_05\",)\n",
    "target_hour = [5]\n",
    "timesteps = [5]\n",
    "train, y_train = create_input_for_models.create(hcm_df, timesteps=timesteps, target_hour=target_hour, test_output=True, dev_output=True, output_path=_model_input_data_path, PROJ_ROOT=PROJ_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-6.6412216e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  8.8788521e-01,  4.6006504e-01,\n",
       "         8.6602539e-01,  5.0000000e-01, -2.4492937e-16,  1.0000000e+00,\n",
       "         9.9853343e-01,  5.4138910e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -5.7251906e-01, -5.6488550e-01, -5.7251906e-01,\n",
       "        -5.7633591e-01, -5.7862598e-01, -5.8396947e-01, -5.9214830e-01,\n",
       "        -5.6870228e-01, -5.5216283e-01, -5.4122138e-01, -5.3712702e-01,\n",
       "        -5.3712702e-01, -5.3712702e-01],\n",
       "       [-6.5648854e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  9.7908407e-01,  2.0345601e-01,\n",
       "         8.6602539e-01,  5.0000000e-01, -2.4492937e-16,  1.0000000e+00,\n",
       "         9.9853343e-01,  5.4138910e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -6.6412216e-01, -6.1832058e-01, -5.9796441e-01,\n",
       "        -5.9541982e-01, -5.9389311e-01, -5.9287530e-01, -5.9541982e-01,\n",
       "        -6.0114503e-01, -5.7930452e-01, -5.6335878e-01, -5.5239415e-01,\n",
       "        -5.4770994e-01, -5.4770994e-01],\n",
       "       [-6.4122134e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  9.9766874e-01, -6.8242416e-02,\n",
       "         8.6602539e-01,  5.0000000e-01, -2.4492937e-16,  1.0000000e+00,\n",
       "         9.9853343e-01,  5.4138910e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -6.5648854e-01, -6.6030532e-01, -6.3104326e-01,\n",
       "        -6.1259544e-01, -6.0763359e-01, -6.0432571e-01, -6.0196292e-01,\n",
       "        -6.0305345e-01, -6.0729432e-01, -5.8702290e-01, -5.7182515e-01,\n",
       "        -5.6106871e-01, -5.5607754e-01],\n",
       "       [-6.4122134e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  9.4226092e-01, -3.3487961e-01,\n",
       "         8.6602539e-01,  5.0000000e-01, -2.4492937e-16,  1.0000000e+00,\n",
       "         9.9853343e-01,  5.4138910e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -6.4122134e-01, -6.4885497e-01, -6.5394402e-01,\n",
       "        -6.3358778e-01, -6.1832058e-01, -6.1323154e-01, -6.0959649e-01,\n",
       "        -6.0687023e-01, -6.0729432e-01, -6.1068702e-01, -5.9195006e-01,\n",
       "        -5.7760817e-01, -5.6215924e-01],\n",
       "       [-6.1832058e-01,  1.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  8.1696987e-01, -5.7668030e-01,\n",
       "         8.6602539e-01,  5.0000000e-01, -2.4492937e-16,  1.0000000e+00,\n",
       "         9.9853343e-01,  5.4138910e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -6.4122134e-01, -6.4122134e-01, -6.4631045e-01,\n",
       "        -6.5076333e-01, -6.3511449e-01, -6.2213743e-01, -6.1723012e-01,\n",
       "        -6.1354959e-01, -6.1068702e-01, -6.1068702e-01, -6.1346287e-01,\n",
       "        -5.9605598e-01, -5.6743002e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.648855  , -0.7251908 , -0.77862597, ..., -0.8015267 ,\n",
       "       -0.8167939 , -0.8015267 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Show graphs and stats here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "Summarize findings here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('aqi': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  },
  "interpreter": {
   "hash": "42a6f2126429ef925a6fad1ea37228e960d97f17ff7e5115d7c9932b5f26640c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}